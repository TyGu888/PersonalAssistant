# LLM 配置 - 支持多 Provider Profile
# 各 profile 可覆盖 agent 超时/重试：llm_call_timeout, llm_http_timeout, llm_max_retries（或 timeout, max_retries）
llm_profiles:
  # 火山引擎方舟 (Doubao)
  ark_doubao-seed2-pro:
    api_key: ${ARK_API_KEY}
    base_url: https://ark.cn-beijing.volces.com/api/v3
    model: ep-20260215211153-86rvm
    media_format: volcengine  # volcengine: image_url + video_url
    extra_params:
      reasoning_effort: medium  # minimal|low|medium|high

  # 火山引擎方舟 (Doubao-code)
  ark_doubao-seed2-code:
    api_key: ${ARK_API_KEY}
    base_url: https://ark.cn-beijing.volces.com/api/v3
    model: ep-20260215215459-2xz66
    media_format: volcengine
    extra_params:
      reasoning_effort: medium  # minimal|low|medium|high


  # DeepSeek Chat (普通对话)
  deepseek_chat:
    api_key: ${DEEPSEEK_API_KEY}
    base_url: https://api.deepseek.com
    model: deepseek-chat
    supports_vision: false
  
  # DeepSeek Reasoner (R1 推理)
  deepseek_reasoner:
    api_key: ${DEEPSEEK_API_KEY}
    base_url: https://api.deepseek.com
    model: deepseek-reasoner
    supports_vision: false
    features:
      preserve_reasoning_content: true  # 多轮对话保留 reasoning_content
  
  # OpenAI
  openai_gpt4o:
    api_key: ${OPENAI_API_KEY}
    base_url: https://api.openai.com/v1
    model: gpt-4o
    # media_format: openai  # 默认值，支持 image_url + input_audio

  # Qwen3 VL (Vision Language Model, 用于 Computer Use grounding)
  # 通过 Dashscope OpenAI-compatible API 或火山引擎等
  qwen3_vl:
    api_key: ${DASHSCOPE_API_KEY}
    base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
    model: qwen-vl-max

# 当前使用的 LLM Profile
llm:
  active: ark_doubao-seed2-pro  # 切换这里即可换模型 (可选: ark_doubao-seed2-code, deepseek_chat, openai_gpt4o 等)
  max_context_tokens: 16000
  max_response_tokens: 8192

# Gateway 配置 (新架构)
gateway:
  enabled: true
  host: "0.0.0.0"
  port: 8080
  # api_key: ${HTTP_API_KEY}  # 取消注释启用 API Key 认证

# Agent 配置 (新架构)
# 超时与重试可在 agent 统一设置，也可在 llm_profiles.<name> 下按模型覆盖
agent:
  wake_interval: 0        # 周期性唤醒间隔（秒），0 = 仅事件驱动
  max_iterations: 50      # 单次对话最大 tool call 循环次数
  llm_call_timeout: 600   # 单次 LLM 调用总超时（秒），含推理/思考时间
  llm_http_timeout: 600   # HTTP 客户端单次请求超时（秒），建议 >= llm_call_timeout
  llm_max_retries: 2      # 请求失败时重试次数

# 数据目录（SQLite + ChromaDB）
data:
  dir: ./data  # 会创建 sessions.db 和 chroma/

# Skills 配置
skills:
  dir: ./skills  # Skills 目录路径
  # 可选：覆盖特定 skill 的配置
  overrides:
    study_coach:
      enabled: true
    default:
      enabled: true
    coding_assistant:
      enabled: true
    project_manager:
      enabled: true
    ppt_assistant:
      enabled: true

# Memory 配置
memory:
  identity_mode: "single_owner"  # "single_owner" | "multi_user"
  max_context_messages: 10  # 上下文最大消息数（向后兼容，按条数截断）
  max_context_tokens: 16000  # 新增：按 token 截断（优先于条数截断）

# Channel 配置
channels:
  telegram:
    enabled: false  # Phase 0 先关闭
    token: ${TELEGRAM_BOT_TOKEN}
    allowed_users: ["968804902337912883"]  # 白名单
  discord:
    enabled: true
    token: ${DISCORD_BOT_TOKEN}
    allowed_users: ["968804902337912883"]  # 白名单
  slack:
    enabled: true
    bot_token: ${SLACK_BOT_TOKEN}   # xoxb-...
    app_token: ${SLACK_APP_TOKEN}   # xapp-...
    allowed_users: []
  feishu:
    enabled: false
    app_id: ${FEISHU_APP_ID}
    app_secret: ${FEISHU_APP_SECRET}
    encrypt_key: ""
    verification_token: ""
    allowed_users: []
  qq:
    enabled: false
    appid: ${QQ_BOT_APPID}
    secret: ${QQ_BOT_SECRET}
    allowed_users: []
  wecom:
    enabled: false
    corp_id: ${WECOM_CORP_ID}
    app_secret: ${WECOM_APP_SECRET}
    agent_id: ${WECOM_AGENT_ID}
    token: ${WECOM_TOKEN}
    encoding_aes_key: ${WECOM_AES_KEY}
    allowed_users: []
  http:
    enabled: false  # HTTP 已迁移到 gateway
    host: "0.0.0.0"
    port: 8080
    api_key: ${HTTP_API_KEY}  # 可选：API Key 认证，为空则不验证

# Channel 专用工具配置
# 当消息来自某个 channel 时，自动将这些工具添加到可用工具列表
# 注意：这些工具需要单独实现，这里只是建立机制
channel_tools:
  discord: [discord_reply_message, discord_add_reaction, discord_create_thread]
  telegram: []
  slack: [slack_reply_in_thread, slack_add_reaction, slack_pin_message]
  feishu: [feishu_reply_message, feishu_add_reaction, feishu_pin_message, feishu_create_chat]
  qq: [qq_add_reaction, qq_pin_message]
  wecom: [wecom_reply_message, wecom_send_to_group, wecom_upload_media, wecom_download_media]

# 路由规则
# 现在只有一个 default agent，所有消息都给全部工具
# Agent 可以通过 read_file 读取 skills/ 目录下的 SKILL.md 获取专业指导
routing:
  - match: {}  # 所有消息
    agent: default
    tools: [
      # 文件操作
      create_file, read_file, list_files, append_file, delete_file, send_file, 
      edit_file, find_files, grep_files,
      # 网络 / 浏览器
      web_search, fetch_url, browser,
      # 定时提醒
      scheduler,
      # Shell / 沙箱
      run_command, shell_session, sandbox,
      # 记忆
      memory,
      # Sub-Agent
      agent,
      # Config 热更新
      config,
      # MCP 动态热插拔
      mcp,
      # Channel (主动发消息 + 通讯录)
      send_message, get_contacts, contact_remove,
      # 企业微信 + 微盘
      wecom_reply_message, wecom_send_to_group, wecom_upload_media, wecom_download_media,
      wedrive_list_spaces, wedrive_space_info, wedrive_create_space, wedrive_rename_space,
      wedrive_list_files, wedrive_file_info, wedrive_create_folder, wedrive_upload_file,
      wedrive_download_file, wedrive_delete_file, wedrive_move_file, wedrive_rename_file,
      # Computer Use (GUI 操作，低层工具已移至 GroundingEngine 内部)
      computer_action
    ]

# Computer Use 配置 (GUI 操作)
computer_use:
  enabled: false                   # 默认关闭，启用前需安装 pyautogui
  vision_profile: qwen3_vl        # 指向 llm_profiles 中的 VL 模型，切换模型只改这里
  vision_backend: vision_api       # 目前支持: vision_api (未来: showui, accessibility)
  max_steps: 15                    # computer_action 默认最大步数
  screenshot_dir: data/screenshots
  action_wait: 0.3                 # 每步操作后等待 UI 更新的时间 (秒)
  memory:
    max_screenshots: 2             # 滑动窗口截图数量
    max_text_history: 50           # 文本动作历史最大条数

# Docker 沙箱配置
sandbox:
  enabled: true  # 默认关闭，启用后 shell 命令将在容器中执行
  image: "personalassistant-sandbox:latest"  # 沙箱镜像
  memory_limit: "512m"  # 内存限制
  cpu_limit: 1.0  # CPU 限制（核数）
  network: "none"  # 网络模式: "none"(无网络) 或 "bridge"(桥接)
  workspace_mount: "./data/workspace"  # 工作目录挂载路径

# MCP (Model Context Protocol) 配置
# 连接外部 MCP Server 复用社区工具
mcp:
  enabled: false  # 默认关闭，启用后加载 MCP Servers
  servers:
    # 示例: 文件系统 Server
    # - name: filesystem
    #   command: npx
    #   args: ["-y", "@modelcontextprotocol/server-filesystem", "./data/workspace"]
    
    # 示例: GitHub Server
    # - name: github
    #   command: npx
    #   args: ["-y", "@modelcontextprotocol/server-github"]
    #   env:
    #     GITHUB_PERSONAL_ACCESS_TOKEN: ${GITHUB_TOKEN}
    
    # 示例: Brave Search Server
    # - name: brave-search
    #   command: npx
    #   args: ["-y", "@modelcontextprotocol/server-brave-search"]
    #   env:
    #     BRAVE_API_KEY: ${BRAVE_API_KEY}

# Agent 定义
agents:
  default:
    prompt: |
      # 通用助手

      ## 角色定义
      你是一个友好、乐于助人的 AI 助手。你可以帮助用户解答问题、聊天、提供建议，以及完成各种日常任务。

      ## 核心职责
      - 回答用户的各种问题
      - 提供有用的建议和信息
      - 帮助用户完成任务
      - 进行友好的日常对话

      ## 交互风格
      - 保持礼貌、耐心和友好
      - 用简洁清晰的语言回复
      - 适时提供额外的有用信息
      - 如果不确定，诚实地说明
      - 避免过于正式或生硬

      ## 工具使用指南

      你的工具使用 action 参数来区分操作。核心工具：

      ### 命令执行
      <important>
      - **run_command**: 单次命令（不保持状态）。沙箱开启时默认在 Docker 容器执行，设 use_sandbox=false 可在宿主机执行。
      - **shell_session(action="start/exec/stop/list")**: 持久化 Shell 会话，保持 cwd 和 env 状态。复杂任务推荐。
      - **sandbox(action="status/stop/copy_to/copy_from")**: 管理 Docker 沙箱容器。
      </important>

      ### 浏览器 (browser)
      browser(action="open/goto/click/fill/snapshot/screenshot/close")
      典型流程：open → goto → snapshot → click/fill → snapshot → close

      ### 其他工具
      - **scheduler**(action="add/list/cancel"): 定时提醒
      - **memory**(action="search/add"): 长期记忆
      - **agent**(action="spawn/list/query/send/stop/history"): 子 Agent
      - **config**(action="get/set/switch_profile/reload_skills"): 运行时配置
      - **mcp**(action="connect/disconnect/list"): MCP 服务器管理

      ## 处理定时任务触发
      当收到 [定时任务触发] 开头的消息时：
      1. 友好地提醒用户该做的事
      2. 设置下一次提醒（scheduler(action="add")，auto_continue=true，默认明天同一时间）
      3. 可选：设置1小时后的追问提醒（auto_continue=false）
